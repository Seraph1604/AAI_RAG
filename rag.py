# -*- coding: utf-8 -*-
"""RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LWKDat0DwJm1TQiIzPg7Z5oHNOYafffp
"""

!pip install -U sentence-transformers faiss-cpu
!pip install pymupdf
!pip install --upgrade torch torchvision torchaudio
!pip install --upgrade sentence-transformers
!pip install google-generativeai

def parse_text(text, chunk_size=750, overlap=50):
    chunks = []
    for i in range(0, len(text), chunk_size - overlap):
        chunk = text[i:i+chunk_size]
        chunks.append(chunk)
    return chunks

import fitz  # PyMuPDF
import re

def extract_text_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    text = text.replace("\xa0", " ")
    text = text.replace("\n", " ")
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^\w\s,.-]', '', text)
    return text

text1 = extract_text_pdf('docs/doc1.pdf')
text2 = extract_text_pdf('docs/doc2.pdf')

docs = []

import pandas as pd
df = pd.read_csv('docs/cards.csv')


for _, row in df.iterrows():
    row_str = [f"{col}: {row[col]}" for col in df.columns]
    row_str = " ".join(row_str)
    docs.append(row_str)
text3 = "\n".join(docs)

docs += parse_text(text1, chunk_size = 500, overlap = 10) + parse_text(text2, chunk_size = 250, overlap = 5)

len(docs)

from sentence_transformers import SentenceTransformer
import numpy as np
import torch

model1 = SentenceTransformer("multi-qa-mpnet-base-cos-v1")
'''
embeddings = model1.encode(docs, convert_to_tensor=True)
# Save embeddings to a file
np.save("embeddings.npy", embeddings.cpu().numpy())
'''
# Later, to load the embeddings:
embeddings = torch.tensor(np.load("embeddings.npy"))

embeddings.shape

import torch
import faiss

dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(embeddings.cpu().numpy())

def search(query, top_k=5):
    query_embedding = model1.encode([query], convert_to_tensor=True)

    query_embedding = query_embedding.cpu().numpy()

    distances, indices = index.search(query_embedding, top_k)
    return indices[0]

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(docs)

def find_similar(query, documents, tfidf_matrix, top_n=5):
    query_vec = vectorizer.transform([query])
    similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()
    top_indices = similarities.argsort()[::-1][:top_n]
    return top_indices

import google.generativeai as genai

with open('docs/api.txt', 'r') as file:
    api_key = file.readline().strip()

genai.configure(api_key = api_key)
model = genai.GenerativeModel('gemini-1.5-flash')

import numpy as np

query = "что обязуется сделать банк?"
results = search(query, 5)
resTFIDF = find_similar(query, docs, tfidf_matrix)
combined_results = np.concatenate((results, resTFIDF))
unique_results = np.unique(combined_results)
question_list = [docs[i] for i in unique_results]
question = 'Каждое предложение ответа пиши в новой строчке. Ответь на вопрос: '+ query + '|'.join(question_list)
response = model.generate_content(question)
print(response.text)